{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "26359bdf-00a9-4280-9ec4-6ca7295148e4",
    "_uuid": "108609d6b29e75ec9f0fe15f66b4336f694c74b2"
   },
   "source": [
    "## VGG implementation with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4eb5ad5-03ba-4fc4-b417-451e30a01fd1",
    "_uuid": "be3002e45fc687fc33e7c7ae9d869ac7ee926b1a"
   },
   "source": [
    "*Python Modules*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "_cell_guid": "0e05b5f8-fc51-404d-a9d2-5197aa283b73",
    "_uuid": "76fd0ec2a5eb7fbe49b51147eabbd109c61279c0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sklearn.svm\n",
    "import sklearn.cross_validation\n",
    "plt.ion() \n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "_cell_guid": "e9d7ef88-fdbd-4b73-b64f-70294976d238",
    "_uuid": "83371f19c7f1e261bb0f9cc71f7a265c37a4c16a",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1074,
     "status": "ok",
     "timestamp": 1525007461873,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "xvsy0IR4wheJ",
    "outputId": "bb02efaa-518c-4342-d6e5-7275a7d7fdd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7500 images under train\n",
      "Loaded 2500 images under test\n",
      "Classes: \n",
      "['beef_tartare', 'caesar_salad', 'chocolate_cake', 'croque_madame', 'escargots', 'fried_calamari', 'macaroni_and_cheese', 'poutine', 'spring_rolls', 'tuna_tartare']\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"C:/Users/Umashanker Deekshith/Google Drive/Germany/Uni-Bonn/Semester 3/Deep Learning for VR/Exercise/DeepLearningWS/project/Deep-Learning-Project/src/images\"\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n",
    "\n",
    "# VGG-16 Takes 224x224 images as input, so we resize all of them\n",
    "data_transforms = {\n",
    "    TRAIN: transforms.Compose([\n",
    "        # Data augmentation is a good practice for the train set\n",
    "        # Here, we randomly crop the image to 224x224 and\n",
    "        # randomly flip it horizontally. \n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    TEST: transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), \n",
    "        transform=data_transforms[x]\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=1,\n",
    "        shuffle=True, num_workers=1\n",
    "    )\n",
    "    for x in [TRAIN, TEST]\n",
    "}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, TEST]}\n",
    "\n",
    "for x in [TRAIN, TEST]:\n",
    "    print(\"Loaded {} images under {}\".format(dataset_sizes[x], x))\n",
    "    \n",
    "print(\"Classes: \")\n",
    "class_names = image_datasets[TRAIN].classes\n",
    "print(image_datasets[TRAIN].classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ad1e66d-dcfc-429a-9664-e61b4d2944cc",
    "_uuid": "80417b6d4f2000be40245a090424b2452e1b78e1",
    "colab_type": "text",
    "id": "6f1fb14iwheO"
   },
   "source": [
    "## Utils\n",
    "\n",
    "Some utility function to visualize the dataset and the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "_cell_guid": "fd84399d-83f9-4af7-8767-fe1d32856493",
    "_uuid": "48e7f7c02cab559638af532e98d371ebd8c89bfa",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1443,
     "status": "ok",
     "timestamp": 1525007467056,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "rphPgOQewheQ",
    "outputId": "0bec4c14-9968-4119-bb75-f896ddc21ebd"
   },
   "outputs": [],
   "source": [
    "# def imshow(inp, title=None):\n",
    "#     inp = inp.numpy().transpose((1, 2, 0))\n",
    "#     # plt.figure(figsize=(10, 10))\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(inp)\n",
    "#     if title is not None:\n",
    "#         plt.title(title)\n",
    "#     plt.pause(0.001)\n",
    "\n",
    "# def show_databatch(inputs, classes):\n",
    "#     out = torchvision.utils.make_grid(inputs)\n",
    "#     imshow(out, title=[class_names[x] for x in classes])\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders[TRAIN]))\n",
    "inputs_test, classes_test = next(iter(dataloaders[TEST]))\n",
    "# show_databatch(inputs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "_cell_guid": "5e6e0c3f-19bd-4034-b408-eeffb9746275",
    "_uuid": "d7785c091b61ab0ddff8556c06bafc5f16037aa4",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "WXgC3SYkwheT"
   },
   "outputs": [],
   "source": [
    "# def visualize_model(vgg, num_images=6):\n",
    "#     was_training = vgg.training\n",
    "    \n",
    "#     # Set model for evaluation\n",
    "#     vgg.train(False)\n",
    "#     vgg.eval() \n",
    "    \n",
    "#     images_so_far = 0\n",
    "\n",
    "#     for i, data in enumerate(dataloaders[TEST]):\n",
    "#         inputs, labels = data\n",
    "#         size = inputs.size()[0]\n",
    "        \n",
    "#         if use_gpu:\n",
    "#             inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "#         else:\n",
    "#             inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "        \n",
    "#         outputs = vgg(inputs)\n",
    "        \n",
    "#         _, preds = torch.max(outputs.data, 1)\n",
    "#         predicted_labels = [preds[j] for j in range(inputs.size()[0])]\n",
    "        \n",
    "#         print(\"Ground truth:\")\n",
    "#         show_databatch(inputs.data.cpu(), labels.data.cpu())\n",
    "#         print(\"Prediction:\")\n",
    "#         show_databatch(inputs.data.cpu(), predicted_labels)\n",
    "        \n",
    "#         del inputs, labels, outputs, preds, predicted_labels\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "#         images_so_far += size\n",
    "#         if images_so_far >= num_images:\n",
    "#             break\n",
    "        \n",
    "#     vgg.train(mode=was_training) # Revert model back to original training state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "_cell_guid": "1b74302a-9418-4472-970f-76591d00cecb",
    "_uuid": "6d1b1cd49e177152940d8f667b9fa5e2e1c5e360",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(vgg, criterion):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    test_batches = len(dataloaders[TEST])\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "    \n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTest batch {}/{}\".format(i, test_batches), end='', flush=True)\n",
    "\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "        inputs, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "\n",
    "        outputs = vgg(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss_test += loss.data[0]\n",
    "        acc_test += torch.sum(preds == labels.data)\n",
    "\n",
    "        del inputs, labels, outputs, preds\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    avg_loss = loss_test / dataset_sizes[TEST]\n",
    "    avg_acc = acc_test / dataset_sizes[TEST]\n",
    "    \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Avg loss (test): {:.4f}\".format(avg_loss))\n",
    "    print(\"Avg acc (test): {:.4f}\".format(avg_acc))\n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "_cell_guid": "4be764f7-24ff-4611-8fc6-31b87e3ed171",
    "_uuid": "480b7181f00142865d3e971c799dd42bc9d1f7e5",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1003
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2623,
     "status": "ok",
     "timestamp": 1525007474565,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "SjHLMTldwheY",
    "outputId": "4c40caae-9d25-47e5-fe17-a4f3f944487e"
   },
   "outputs": [],
   "source": [
    "def set_up_network(net, freeze_training = True):\n",
    "    if net == 'vgg16':\n",
    "    # Load the pretrained model from pytorch\n",
    "        network = models.vgg16(pretrained=True)\n",
    "\n",
    "        # Freeze training for all layers\n",
    "        # Newly created modules have require_grad=True by default\n",
    "        if freeze_training:\n",
    "            for param in network.features.parameters():\n",
    "                param.require_grad = False\n",
    "\n",
    "        \n",
    "        features = list(network.classifier.children())[:-5] # Remove last layer\n",
    "        network.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "        # print(vgg16)\n",
    "    \n",
    "    elif net == 'alexnet':\n",
    "        network = models.alexnet(pretrained=True)\n",
    "        if freeze_training:\n",
    "            for param in network.features.parameters():\n",
    "                param.require_grad = False\n",
    "        \n",
    "        features = list(network.classifier.children())[:-4] # Remove last layer\n",
    "        network.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "        print(alex_net)\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vgg16 = set_up_network('vgg16', freeze_training = True)\n",
    "alex_net = set_up_network('alexnet', freeze_training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "_cell_guid": "f45bda67-096e-4de9-a801-98742c34207c",
    "_uuid": "bd59ea5c500e55b3ae4bd9cdfeae01bd50818668",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Xuaq38UOwhec"
   },
   "outputs": [],
   "source": [
    "# If you want to train the model for more than 2 epochs, set this to True after the first run\n",
    "resume_training = False\n",
    "\n",
    "if resume_training:\n",
    "    print(\"Loading pretrained model..\")\n",
    "    vgg16.load_state_dict(torch.load('../input/vgg16-transfer-learning-pytorch/VGG16_v2-OCT_Retina.pt'))\n",
    "    print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "_cell_guid": "df23921b-f26e-496a-9a71-cdf2a9daa34e",
    "_uuid": "45d872d00fcfe93de8938b8741b4526af971c62b",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "HTJWo25nwhef"
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    vgg16.cuda() #.cuda() will move everything to the GPU side\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "_cell_guid": "f7aec745-2087-4f60-987d-a34a995fd6a9",
    "_uuid": "7732406aae91a82348fcb830a5ff5785d22526fb",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1986,
     "status": "ok",
     "timestamp": 1525007488210,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "jSa-X3XVwheo",
    "outputId": "d6f338d4-5379-4fe8-aaec-cc8141b7cbb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test before training\n"
     ]
    }
   ],
   "source": [
    "print(\"Test before training\")\n",
    "# eval_model(vgg16, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "_cell_guid": "dabed264-9a90-4888-ad3c-65924ad9c80d",
    "_uuid": "eff4aa2d97fd5443195ae2a2cd43c5f73e6775a3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize_model(vgg16) #test before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "_cell_guid": "8f6936eb-ae6f-44ee-90a9-c7f817ba6eda",
    "_uuid": "abe5dc35b31e7971e7d63637866132f89e7d011d",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "lHkiBU5fwhet"
   },
   "outputs": [],
   "source": [
    "def train_model(vgg, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "    \n",
    "    train_batches = len(dataloaders[TRAIN])\n",
    "    val_batches = len(dataloaders[VAL])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "        \n",
    "        for i, data in enumerate(dataloaders[TRAIN]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "                \n",
    "            # Use half training dataset\n",
    "            if i >= train_batches / 2:\n",
    "                break\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.data[0]\n",
    "            acc_train += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        print()\n",
    "        # * 2 as we only used half of the dataset\n",
    "        avg_loss = loss_train * 2 / dataset_sizes[TRAIN]\n",
    "        avg_acc = acc_train * 2 / dataset_sizes[TRAIN]\n",
    "        \n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "            \n",
    "        for i, data in enumerate(dataloaders[VAL]):\n",
    "            if i % 100 == 0:\n",
    "                print(\"\\rValidation batch {}/{}\".format(i, val_batches), end='', flush=True)\n",
    "                \n",
    "            inputs, labels = data\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda(), volatile=True), Variable(labels.cuda(), volatile=True)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs, volatile=True), Variable(labels, volatile=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = vgg(inputs)\n",
    "            \n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_val += loss.data[0]\n",
    "            acc_val += torch.sum(preds == labels.data)\n",
    "            \n",
    "            del inputs, labels, outputs, preds\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        avg_loss_val = loss_val / dataset_sizes[VAL]\n",
    "        avg_acc_val = acc_val / dataset_sizes[VAL]\n",
    "        \n",
    "        print()\n",
    "        print(\"Epoch {} result: \".format(epoch))\n",
    "        print(\"Avg loss (train): {:.4f}\".format(avg_loss))\n",
    "        print(\"Avg acc (train): {:.4f}\".format(avg_acc))\n",
    "        print(\"Avg loss (val): {:.4f}\".format(avg_loss_val))\n",
    "        print(\"Avg acc (val): {:.4f}\".format(avg_acc_val))\n",
    "        print('-' * 10)\n",
    "        print()\n",
    "        \n",
    "        if avg_acc_val > best_acc:\n",
    "            best_acc = avg_acc_val\n",
    "            best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print()\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc))\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(ipnet, train_batches = 10):\n",
    "    \n",
    "    imgfeatures = []\n",
    "    imglabels = []\n",
    "    for i, data in enumerate(dataloaders[TRAIN]):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='', flush=True)\n",
    "\n",
    "        # Use half training dataset\n",
    "        if i > train_batches:\n",
    "            break\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        feature = ipnet(inputs)\n",
    "        print(\"The shape of output is: \", feature.shape)\n",
    "        print(labels)\n",
    "        imgfeatures.append(feature.detach().numpy().flatten())\n",
    "        imglabels.append(labels.detach().numpy())\n",
    "        del inputs, labels, feature\n",
    "\n",
    "    return imgfeatures, imglabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_features_to_SVM(features, labels, train_batch_size, K=5 ):\n",
    "    print(\"The shape of the class is\", classes.shape)\n",
    "    kf = sklearn.cross_validation.KFold(train_batch_size, n_folds=K)\n",
    "    print(\"The split information is: \", kf)\n",
    "    scores = []\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    i=0\n",
    "    for train, test in kf:\n",
    "        print(train)\n",
    "        print(test)\n",
    "        print(i,\"/\",K)\n",
    "        i+=1\n",
    "        model = sklearn.svm.SVC(C=100)#, C=1, gamma=0)\n",
    "        model.fit(features[train, :], labels[train])\n",
    "        s=model.score(features[test, :], labels[test])\n",
    "        print(\"The score for this classification is: \", s)\n",
    "        scores.append(s)\n",
    "    return np.mean(scores), np.std(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "_cell_guid": "53eeb478-e106-49be-9682-0173e76640f8",
    "_uuid": "a0ddf54b1c45b7c61724cbe1e74ca0628f8b1d8e",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1525023518627,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "r1-I_IUUwhew",
    "outputId": "b764e48a-00fd-4eb5-f592-f4386a875ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 0/5.0The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([1])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([1])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([7])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([1])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([1])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([6])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([6])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([3])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([0])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([5])\n",
      "The shape of output is:  torch.Size([1, 4096])\n",
      "tensor([9])\n",
      "The shape of the class is torch.Size([1])\n",
      "The split information is:  sklearn.cross_validation.KFold(n=10, n_folds=5, shuffle=False, random_state=None)\n",
      "(11, 4096)\n",
      "(11, 1)\n",
      "[2 3 4 5 6 7 8 9]\n",
      "[0 1]\n",
      "0 / 5\n",
      "The score for this classification is:  1.0\n",
      "[0 1 4 5 6 7 8 9]\n",
      "[2 3]\n",
      "1 / 5\n",
      "The score for this classification is:  0.5\n",
      "[0 1 2 3 6 7 8 9]\n",
      "[4 5]\n",
      "2 / 5\n",
      "The score for this classification is:  1.0\n",
      "[0 1 2 3 4 5 8 9]\n",
      "[6 7]\n",
      "3 / 5\n",
      "The score for this classification is:  0.0\n",
      "[0 1 2 3 4 5 6 7]\n",
      "[8 9]\n",
      "4 / 5\n",
      "The score for this classification is:  0.0\n",
      "0.5 0.4472135954999579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-205-39290a55a82b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimgfeatures_vgg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimglabels_vgg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmean_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_features_to_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgfeatures_vgg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimglabels_vgg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The mean and standard deviation of classification for vgg 16 is: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "train_batch_size = 10\n",
    "\n",
    "imgfeatures_vgg, imglabels_vgg = get_features(vgg16, train_batch_size)\n",
    "mean_accuracy, sd = fit_features_to_SVM(imgfeatures_vgg, imglabels_vgg, train_batch_size, K=5 )\n",
    "print(\"The mean and standard deviation of classification for vgg 16 is: \",mean_accuracy, sd)\n",
    "\n",
    "imgfeatures_an, imglabels_an = get_features(alex_net, train_batch_size)\n",
    "mean_accuracy, sd = fit_features_to_SVM(imgfeatures_an, imglabels_an, train_batch_size, K=5 )\n",
    "print(\"The mean and standard deviation of classification for alexnet is: \",mean_accuracy, sd)\n",
    "\n",
    "\n",
    "# vgg16 = train_model(vgg16, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=2)\n",
    "torch.save(vgg16.state_dict(), 'VGG16_v2-OCT_Retina_half_dataset.pt')\n",
    "torch.save(alex_net.state_dict(), 'ALEXNET_v2-OCT_Retina_half_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f8d905fe-9f7f-484b-b926-9931ca887e34",
    "_uuid": "2803b24b7002a785833d300413e3bd8891f398f9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# eval_model(vgg16, criterion)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "VGG16_v2-OCT2017_Retina.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
